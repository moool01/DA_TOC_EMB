{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Corpus Read\n",
    "with open('corpus_non_split.txt', 'r', encoding='utf-8') as f:\n",
    "    corpus = f.read()\n",
    "\n",
    "# Corpus 정제\n",
    "repr_pattern  = '[^a-zA-Z가-힣\\d\\n]'\n",
    "re_corpus = re.sub(pattern=repr_pattern, repl=' ', string=corpus)\n",
    "re_corpus = re.sub(pattern='\\s{2,}', repl=' ', string=re_corpus)\n",
    "\n",
    "# Corpus 저장\n",
    "with open('re_corpus.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(re_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import SentencePieceBPETokenizer\n",
    "\n",
    "s_tokenizer = SentencePieceBPETokenizer()\n",
    "\n",
    "data_file = 're_corpus.txt'\n",
    "vocab_size = 30000\n",
    "limit_alphabet = 6000\n",
    "min_frequency = 3\n",
    "\n",
    "s_tokenizer.train(files=data_file,\n",
    "                  vocab_size=vocab_size,\n",
    "                  limit_alphabet=limit_alphabet,\n",
    "                  min_frequency=min_frequency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰화 결과 : ['▁행복주택', '에서', '▁미소금융', '이나', '▁햇살론', '을', '▁농협', '은행', '에서', '▁담보', '대출', '을']\n",
      "정수 인코딩 : [3744, 849, 5696, 1777, 2233, 526, 2403, 1142, 849, 3684, 1401, 526]\n",
      "디코딩 : 행복주택에서 미소금융이나 햇살론을 농협은행에서 담보대출을\n",
      "추가된 단어 수: 7253\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 결과 확인\n",
    "encoded = s_tokenizer.encode(\"행복주택에서 미소금융이나 햇살론을 농협은행에서 담보대출을\")\n",
    "print('토큰화 결과 :',encoded.tokens)\n",
    "print('정수 인코딩 :',encoded.ids)\n",
    "print('디코딩 :',s_tokenizer.decode(encoded.ids))\n",
    "\n",
    "# 결과 저장\n",
    "s_tokenizer.save_model('./tokenizer/')\n",
    "# >>> ['./tokenizer/vocab.json', './tokenizer/merges.txt']\n",
    "\n",
    "# vocabulary 확인\n",
    "added_vocab = pd.read_json('./tokenizer/vocab.json', orient='index')\n",
    "print(\"추가된 단어 수:\", len(added_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "No sentence-transformers model found with name /Users/jk/.cache/torch/sentence_transformers/BM-K_KoSimCSE-roberta-multitask. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 4202, 12636, 27135, 5658, 14554, 15351, 9778, 2570, 2069, 6470, 4701, 27135, 6484, 2104, 2102, 2069, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 모델 불러오기\n",
    "\n",
    "base_model_path = \"BM-K/KoSimCSE-roberta-multitask\"\n",
    "# 내가 사용하는 모델이다. 자신이 사용할 (허깅페이스의) 모델 이름 혹은 그 경로를 입력한다.\n",
    "# 실행만 해볼거면 'all-MiniLM-L6-v2' 같은 기본 모델을 써도 된다.\n",
    "model = SentenceTransformer(base_model_path)\n",
    "\n",
    "# 임베딩 모델\n",
    "word_embedding_model = model._first_module()\n",
    "\n",
    "# Adaptation 하기 전 Tokenize 결과\n",
    "test_sentence = '행복주택에서 미소금융이나 햇살론을 농협은행에서 담보대출을'\n",
    "word_embedding_model.tokenizer(test_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f27d7f9a93497db805eff5505fe420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/764 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f588b33a874525850a908c3c497d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512335dcd2fe4972b55c7effade2fb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9354182e1340494e808746f3ba30e88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa733ac5f6e4c4a923153f185a7d5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e926b29da2264ea8a99796f4fece93e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['행복', '##주택', '##에서', '미소', '##금융', '##이나', '햇살', '##론', '##을', '농협', '##은행', '##에서', '담보', '##대', '##출', '##을']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# 토큰화된 결과 확인하기 (Adaptation 적용 전)\n",
    "\n",
    "# base_model_path = \"BM-K/KoSimCSE-roberta-multitask\"\n",
    "model_base = AutoModel.from_pretrained(base_model_path)\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "print(tokenizer_base.tokenize(test_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10번째 중....7\n",
      "20번째 중....H\n",
      "30번째 중....R\n",
      "40번째 중....b\n",
      "50번째 중....l\n",
      "60번째 중....w\n",
      "70번째 중....갑\n",
      "80번째 중....거\n",
      "90번째 중....결\n",
      "100번째 중....곳\n",
      "110번째 중....군\n",
      "120번째 중....글\n",
      "130번째 중....께\n",
      "140번째 중....난\n",
      "150번째 중....냄\n",
      "160번째 중....념\n",
      "170번째 중....뇨\n",
      "180번째 중....닉\n",
      "190번째 중....달\n",
      "200번째 중....덧\n",
      "210번째 중....되\n",
      "220번째 중....듀\n",
      "230번째 중....따\n",
      "240번째 중....란\n",
      "250번째 중....량\n",
      "260번째 중....력\n",
      "270번째 중....롤\n",
      "280번째 중....륙\n",
      "290번째 중....릭\n",
      "300번째 중....말\n",
      "310번째 중....먼\n",
      "320번째 중....모\n",
      "330번째 중....물\n",
      "340번째 중....밖\n",
      "350번째 중....버\n",
      "360번째 중....벽\n",
      "370번째 중....봇\n",
      "380번째 중....붙\n",
      "390번째 중....빼\n",
      "400번째 중....상\n",
      "410번째 중....성\n",
      "420번째 중....솔\n",
      "430번째 중....쉼\n",
      "440번째 중....식\n",
      "450번째 중....쓰\n",
      "460번째 중....앓\n",
      "470번째 중....야\n",
      "480번째 중....엇\n",
      "490번째 중....엽\n",
      "500번째 중....와\n",
      "510번째 중....운\n",
      "520번째 중....윗\n",
      "530번째 중....응\n",
      "540번째 중....있\n",
      "550번째 중....쟁\n",
      "560번째 중....제\n",
      "570번째 중....죄\n",
      "580번째 중....직\n",
      "590번째 중....착\n",
      "600번째 중....척\n",
      "610번째 중....촉\n",
      "620번째 중....충\n",
      "630번째 중....침\n",
      "640번째 중....컴\n",
      "650번째 중....쿠\n",
      "660번째 중....킴\n",
      "670번째 중....택\n",
      "680번째 중....토\n",
      "690번째 중....트\n",
      "700번째 중....판\n",
      "710번째 중....평\n",
      "720번째 중....풍\n",
      "730번째 중....하\n",
      "740번째 중....했\n",
      "750번째 중....혁\n",
      "760번째 중....홈\n",
      "770번째 중....횟\n",
      "780번째 중....흥\n",
      "790번째 중....▁신\n",
      "800번째 중....장애\n",
      "810번째 중....▁내\n",
      "820번째 중....▁제\n",
      "830번째 중....▁의\n",
      "840번째 중....▁4\n",
      "850번째 중....에서\n",
      "860번째 중....▁인\n",
      "870번째 중....▁후\n",
      "880번째 중....▁일\n",
      "890번째 중....▁가능\n",
      "900번째 중....상담센터\n",
      "910번째 중....▁근로\n",
      "920번째 중....▁주민\n",
      "930번째 중....▁진\n",
      "940번째 중....▁서\n",
      "950번째 중....▁예\n",
      "960번째 중....공단\n",
      "970번째 중....▁18\n",
      "980번째 중....피해\n",
      "990번째 중....▁000원\n",
      "1000번째 중....▁포\n",
      "1010번째 중....▁동\n",
      "1020번째 중....▁따라\n",
      "1030번째 중....▁여성\n",
      "1040번째 중....▁통해\n",
      "1050번째 중....▁교\n",
      "1060번째 중....위소득\n",
      "1070번째 중....▁보호\n",
      "1080번째 중....▁11\n",
      "1090번째 중....프로그램\n",
      "1100번째 중....▁주거\n",
      "1110번째 중....장학\n",
      "1120번째 중....▁한부모\n",
      "1130번째 중....▁있습니다\n",
      "1140번째 중....▁부모\n",
      "1150번째 중....내용\n",
      "1160번째 중....됩니다\n",
      "1170번째 중....근로자\n",
      "1180번째 중....▁자동\n",
      "1190번째 중....▁연계\n",
      "1200번째 중....▁위한\n",
      "1210번째 중....▁청년\n",
      "1220번째 중....비용\n",
      "1230번째 중....12\n",
      "1240번째 중....▁지원내용\n",
      "1250번째 중....▁03\n",
      "1260번째 중....가정\n",
      "1270번째 중....▁카드\n",
      "1280번째 중....▁전세\n",
      "1290번째 중....콜센터\n",
      "1300번째 중....19\n",
      "1310번째 중....▁에서\n",
      "1320번째 중....▁퇴\n",
      "1330번째 중....▁치\n",
      "1340번째 중....▁장기\n",
      "1350번째 중....▁1588\n",
      "1360번째 중....▁범\n",
      "1370번째 중....▁본인부담금\n",
      "1380번째 중....▁지자체\n",
      "1390번째 중....90\n",
      "1400번째 중....▁달\n",
      "1410번째 중....▁보훈지\n",
      "1420번째 중....▁H\n",
      "1430번째 중....▁등의\n",
      "1440번째 중....▁편\n",
      "1450번째 중....▁월평균\n",
      "1460번째 중....▁어려\n",
      "1470번째 중....▁부양\n",
      "1480번째 중....년도\n",
      "1490번째 중....▁모바일\n",
      "1500번째 중....구성원\n",
      "1510번째 중....▁부담\n",
      "1520번째 중....75\n",
      "1530번째 중....▁가능합니다\n",
      "1540번째 중....떻게\n",
      "1550번째 중....▁보증\n",
      "1560번째 중....▁국민행복\n",
      "1570번째 중....육아\n",
      "1580번째 중....▁의료기관\n",
      "1590번째 중....2만\n",
      "1600번째 중....▁중앙\n",
      "1610번째 중....▁가정폭력\n",
      "1620번째 중....너지\n",
      "1630번째 중....▁023\n",
      "1640번째 중....▁독립\n",
      "1650번째 중....에는\n",
      "1660번째 중....▁단위\n",
      "1670번째 중....▁약\n",
      "1680번째 중....▁이상인\n",
      "1690번째 중....▁문화누리카드\n",
      "1700번째 중....▁형\n",
      "1710번째 중....▁자산\n",
      "1720번째 중....▁종사\n",
      "1730번째 중....▁B\n",
      "1740번째 중....법률\n",
      "1750번째 중....▁고령\n",
      "1760번째 중....▁도시근로자\n",
      "1770번째 중....▁육아\n",
      "1780번째 중....자산\n",
      "1790번째 중....▁12개월\n",
      "1800번째 중....▁의료급여수급자\n",
      "1810번째 중....▁NH농\n",
      "1820번째 중....▁야간\n",
      "1830번째 중....지원금\n",
      "1840번째 중....▁모두\n",
      "1850번째 중....포츠강좌\n",
      "1860번째 중....상금\n",
      "1870번째 중....▁1차\n",
      "1880번째 중....▁최초\n",
      "1890번째 중....▁사회적\n",
      "1900번째 중....21\n",
      "1910번째 중....보훈\n",
      "1920번째 중....▁수도\n",
      "1930번째 중....▁차량\n",
      "1940번째 중....1388\n",
      "1950번째 중....▁폐\n",
      "1960번째 중....▁중독\n",
      "1970번째 중....▁동일\n",
      "1980번째 중....▁고객상담센터\n",
      "1990번째 중....▁권\n",
      "2000번째 중....성공\n",
      "2010번째 중....학대\n",
      "2020번째 중....▁학업\n",
      "2030번째 중....▁농촌\n",
      "2040번째 중....48\n",
      "2050번째 중....진단\n",
      "2060번째 중....▁전북\n",
      "2070번째 중....▁청소년상담\n",
      "2080번째 중....▁당해\n",
      "2090번째 중....▁민간\n",
      "2100번째 중....▁탈\n",
      "2110번째 중....확인\n",
      "2120번째 중....▁40만\n",
      "2130번째 중....▁장학금\n",
      "2140번째 중....▁세대구성원\n",
      "2150번째 중....▁취약계층\n",
      "2160번째 중....▁용\n",
      "2170번째 중....벌이\n",
      "2180번째 중....플러스\n",
      "2190번째 중....▁의원\n",
      "2200번째 중....▁75\n",
      "2210번째 중....2290\n",
      "2220번째 중....▁카드사\n",
      "2230번째 중....▁우울증\n",
      "2240번째 중....▁꿈\n",
      "2250번째 중....결과\n",
      "2260번째 중....틈새\n",
      "2270번째 중....▁신청방법\n",
      "2280번째 중....▁150만\n",
      "2290번째 중....▁소속\n",
      "2300번째 중....▁1366\n",
      "2310번째 중....▁무주택자\n",
      "2320번째 중....▁할인\n",
      "2330번째 중....▁우선지원대상기업\n",
      "2340번째 중....▁책\n",
      "2350번째 중....비는\n",
      "2360번째 중....직업\n",
      "2370번째 중....▁지원됩니다\n",
      "2380번째 중....▁경감\n",
      "2390번째 중....▁단체\n",
      "2400번째 중....▁교과\n",
      "2410번째 중....▁강좌\n",
      "2420번째 중....▁최저임금\n",
      "2430번째 중....28\n",
      "2440번째 중....▁표\n",
      "2450번째 중....사건\n",
      "2460번째 중....조정\n",
      "2470번째 중....▁2개월\n",
      "2480번째 중....▁인턴\n",
      "2490번째 중....▁조건\n",
      "2500번째 중....▁1644\n",
      "2510번째 중....▁서민금융콜센터\n",
      "2520번째 중....▁근무\n",
      "2530번째 중....et\n",
      "2540번째 중....단체\n",
      "2550번째 중....연도\n",
      "2560번째 중....재해\n",
      "2570번째 중....하시\n",
      "2580번째 중....▁사항\n",
      "2590번째 중....▁0730\n",
      "2600번째 중....▁상황\n",
      "2610번째 중....▁장해\n",
      "2620번째 중....▁영아\n",
      "2630번째 중....의료기관\n",
      "2640번째 중....▁학기별\n",
      "2650번째 중....▁소재지\n",
      "2660번째 중....900\n",
      "2670번째 중....▁홈\n",
      "2680번째 중....기별\n",
      "2690번째 중....북하나\n",
      "2700번째 중....지사\n",
      "2710번째 중....▁원하는\n",
      "2720번째 중....▁고시\n",
      "2730번째 중....건강검진\n",
      "2740번째 중....▁성장\n",
      "2750번째 중....▁확인서\n",
      "2760번째 중....▁접속\n",
      "2770번째 중....▁당시\n",
      "2780번째 중....▁협약\n",
      "2790번째 중....▁곤란한\n",
      "2800번째 중....▁여성가족부\n",
      "2810번째 중....▁놀\n",
      "2820번째 중....▁역량\n",
      "2830번째 중....상공\n",
      "2840번째 중....일부\n",
      "2850번째 중....플루엔\n",
      "2860번째 중....▁3회\n",
      "2870번째 중....복지서비스\n",
      "2880번째 중....▁있음\n",
      "2890번째 중....▁소급\n",
      "2900번째 중....▁등록한\n",
      "2910번째 중....▁동반\n",
      "2920번째 중....▁11만\n",
      "2930번째 중....의료센터\n",
      "2940번째 중....▁활동지원\n",
      "2950번째 중....▁충족하는\n",
      "2960번째 중....수준에\n",
      "2970번째 중....▁중장년\n",
      "2980번째 중....▁검정고시\n",
      "2990번째 중....Mo\n",
      "3000번째 중....▁착\n",
      "3010번째 중....과학\n",
      "3020번째 중....실습\n",
      "3030번째 중....장치\n",
      "3040번째 중....플란트\n",
      "3050번째 중....▁자연\n",
      "3060번째 중....▁내에\n",
      "3070번째 중....소득자\n",
      "3080번째 중....▁경우에는\n",
      "3090번째 중....▁상급\n",
      "3100번째 중....▁운동\n",
      "3110번째 중....▁건강관리\n",
      "3120번째 중....▁주거지원\n",
      "3130번째 중....▁진단을\n",
      "3140번째 중....▁학자금지원\n",
      "3150번째 중....▁현장실습\n",
      "3160번째 중....▁형제\n",
      "3170번째 중....▁고엽제후\n",
      "3180번째 중....▁승용자동차\n",
      "3190번째 중....36\n",
      "3200번째 중....▁와\n",
      "3210번째 중....관서\n",
      "3220번째 중....모임\n",
      "3230번째 중....수행\n",
      "3240번째 중....일수\n",
      "3250번째 중....중단\n",
      "3260번째 중....항목\n",
      "3270번째 중....▁대지급금\n",
      "3280번째 중....▁자로서\n",
      "3290번째 중....▁5일\n",
      "3300번째 중....▁정도\n",
      "3310번째 중....▁인건비\n",
      "3320번째 중....▁청소년쉼터\n",
      "3330번째 중....▁고용유지\n",
      "3340번째 중....▁보훈관서\n",
      "3350번째 중....▁감소\n",
      "3360번째 중....▁세대원\n",
      "3370번째 중....▁시설매입\n",
      "3380번째 중....▁2023년부터\n",
      "3390번째 중....▁앱을\n",
      "3400번째 중....▁학대피해\n",
      "3410번째 중....▁판정자\n",
      "3420번째 중....▁노후준비\n",
      "3430번째 중....▁특수임무유공자\n",
      "3440번째 중....제분유\n",
      "3450번째 중....29\n",
      "3460번째 중....ly\n",
      "3470번째 중....▁올\n",
      "3480번째 중....구매\n",
      "3490번째 중....로금\n",
      "3500번째 중....산업인\n",
      "3510번째 중....일러\n",
      "3520번째 중....토킹\n",
      "3530번째 중....▁지원구간\n",
      "3540번째 중....▁자궁\n",
      "3550번째 중....▁시세\n",
      "3560번째 중....▁고교\n",
      "3570번째 중....▁부채\n",
      "3580번째 중....▁미취업\n",
      "3590번째 중....▁입영\n",
      "3600번째 중....▁다르\n",
      "3610번째 중....▁장애등급\n",
      "3620번째 중....▁종결\n",
      "3630번째 중....▁적응\n",
      "3640번째 중....▁노인맞춤\n",
      "3650번째 중....▁발급받\n",
      "3660번째 중....▁특수형태\n",
      "3670번째 중....▁스토킹\n",
      "3680번째 중....능력이\n",
      "3690번째 중....▁도시가스\n",
      "3700번째 중....▁0236\n",
      "3710번째 중....▁희귀난치\n",
      "3720번째 중....▁농촌지역\n",
      "3730번째 중....▁잔액\n",
      "3740번째 중....▁디지털배움터\n",
      "3750번째 중....▁학점은행제\n",
      "3760번째 중....youth\n",
      "3770번째 중....077\n",
      "3780번째 중....Net\n",
      "3790번째 중....▁좋\n",
      "3800번째 중....갈등\n",
      "3810번째 중....근용\n",
      "3820번째 중....릭시스템\n",
      "3830번째 중....백신\n",
      "3840번째 중....성질환\n",
      "3850번째 중....여행\n",
      "3860번째 중....재생에너지\n",
      "3870번째 중....축물\n",
      "3880번째 중....해서\n",
      "3890번째 중....▁지원제외\n",
      "3900번째 중....▁35\n",
      "3910번째 중....▁전동\n",
      "3920번째 중....▁국고\n",
      "3930번째 중....▁정기\n",
      "3940번째 중....▁재판정\n",
      "3950번째 중....▁사업단\n",
      "3960번째 중....▁2015\n",
      "3970번째 중....▁이용을\n",
      "3980번째 중....▁받으\n",
      "3990번째 중....▁산후\n",
      "4000번째 중....▁가정의\n",
      "4010번째 중....▁교정\n",
      "4020번째 중....▁하위\n",
      "4030번째 중....▁치료회복\n",
      "4040번째 중....▁충북\n",
      "4050번째 중....취업지원센터\n",
      "4060번째 중....▁상이등급\n",
      "4070번째 중....▁모집공고\n",
      "4080번째 중....▁시도교육청\n",
      "4090번째 중....▁고객센터\n",
      "4100번째 중....▁0234\n",
      "4110번째 중....▁형성\n",
      "4120번째 중....▁운전교육\n",
      "4130번째 중....▁시간제보육\n",
      "4140번째 중....▁권리\n",
      "4150번째 중....▁중장기\n",
      "4160번째 중....▁290원\n",
      "4170번째 중....케어센터\n",
      "4180번째 중....▁야간12시간보육료\n",
      "4190번째 중....▁16003456\n",
      "4200번째 중....▁산림복지서비스이용권\n",
      "4210번째 중....323\n",
      "4220번째 중....ck\n",
      "4230번째 중....▁골\n",
      "4240번째 중....▁축\n",
      "4250번째 중....객선\n",
      "4260번째 중....귀국\n",
      "4270번째 중....라면\n",
      "4280번째 중....명령\n",
      "4290번째 중....사관\n",
      "4300번째 중....수훈\n",
      "4310번째 중....유공\n",
      "4320번째 중....잇몸\n",
      "4330번째 중....지자\n",
      "4340번째 중....표준\n",
      "4350번째 중....행동\n",
      "4360번째 중....▁대응\n",
      "4370번째 중....▁사건\n",
      "4380번째 중....▁중이거나\n",
      "4390번째 중....▁주기\n",
      "4400번째 중....지원과\n",
      "4410번째 중....▁고정\n",
      "4420번째 중....▁연결\n",
      "4430번째 중....▁인식\n",
      "4440번째 중....▁기준은\n",
      "4450번째 중....▁일용\n",
      "4460번째 중....▁7월\n",
      "4470번째 중....▁소멸\n",
      "4480번째 중....▁진정\n",
      "4490번째 중....▁고용위기\n",
      "4500번째 중....▁국민내일\n",
      "4510번째 중....▁이내인\n",
      "4520번째 중....▁13세\n",
      "4530번째 중....▁사회복무요원\n",
      "4540번째 중....▁도래\n",
      "4550번째 중....▁하이\n",
      "4560번째 중....▁복지시설\n",
      "4570번째 중....▁세대를\n",
      "4580번째 중....▁않고\n",
      "4590번째 중....▁정보는\n",
      "4600번째 중....▁출생일\n",
      "4610번째 중....▁저소득가구의\n",
      "4620번째 중....▁남은\n",
      "4630번째 중....▁결정을\n",
      "4640번째 중....▁모바일앱\n",
      "4650번째 중....▁정책자료\n",
      "4660번째 중....▁소득인정액\n",
      "4670번째 중....▁담당자\n",
      "4680번째 중....▁휴대폰\n",
      "4690번째 중....▁신한카드\n",
      "4700번째 중....▁여성기업종합지원센터\n",
      "4710번째 중....▁HPV2\n",
      "4720번째 중....▁청소년상담1388\n",
      "4730번째 중....▁의뢰서\n",
      "4740번째 중....▁정규직\n",
      "4750번째 중....▁인턴십\n",
      "4760번째 중....▁분만취약\n",
      "4770번째 중....▁스마트폰\n",
      "4780번째 중....▁0221005\n",
      "4790번째 중....▁배려대상자\n",
      "4800번째 중....▁저렴하게\n",
      "4810번째 중....▁장애인직업재활시설\n",
      "4820번째 중....콘텐츠\n",
      "4830번째 중....▁시설전환비\n",
      "4840번째 중....20만\n",
      "4850번째 중....86\n",
      "4860번째 중....ebc\n",
      "4870번째 중....▁X\n",
      "4880번째 중....▁핵\n",
      "4890번째 중....경부\n",
      "4900번째 중....규정\n",
      "4910번째 중....남성\n",
      "4920번째 중....동포\n",
      "4930번째 중....뜰폰\n",
      "4940번째 중....메일\n",
      "4950번째 중....부가\n",
      "4960번째 중....산식품\n",
      "4970번째 중....시까지\n",
      "4980번째 중....외의\n",
      "4990번째 중....재난지역\n",
      "5000번째 중....중인\n",
      "5010번째 중....킴이\n",
      "5020번째 중....하세요\n",
      "5030번째 중....훈장\n",
      "5040번째 중....▁이외의\n",
      "5050번째 중....▁대도시\n",
      "5060번째 중....▁원월\n",
      "5070번째 중....▁사할린\n",
      "5080번째 중....▁350\n",
      "5090번째 중....▁전부\n",
      "5100번째 중....복지법\n",
      "5110번째 중....▁64\n",
      "5120번째 중....▁46\n",
      "5130번째 중....▁024\n",
      "5140번째 중....▁재료\n",
      "5150번째 중....▁유사한\n",
      "5160번째 중....▁미술\n",
      "5170번째 중....▁해양수\n",
      "5180번째 중....▁어느\n",
      "5190번째 중....▁출퇴\n",
      "5200번째 중....▁소견서\n",
      "5210번째 중....▁여가\n",
      "5220번째 중....▁취업희망\n",
      "5230번째 중....▁비정규직\n",
      "5240번째 중....▁900만\n",
      "5250번째 중....▁무료법률\n",
      "5260번째 중....▁적절\n",
      "5270번째 중....▁주택구입\n",
      "5280번째 중....▁추나요법\n",
      "5290번째 중....▁훈련은\n",
      "5300번째 중....▁10월\n",
      "5310번째 중....▁면지역\n",
      "5320번째 중....▁선정된\n",
      "5330번째 중....▁환자의\n",
      "5340번째 중....▁수급자에게\n",
      "5350번째 중....12급\n",
      "5360번째 중....▁2435\n",
      "5370번째 중....청소년지원센터\n",
      "5380번째 중....▁특별한\n",
      "5390번째 중....▁반환\n",
      "5400번째 중....▁1일20\n",
      "5410번째 중....▁부양자녀\n",
      "5420번째 중....▁재활훈련\n",
      "5430번째 중....▁북한이탈주민정착\n",
      "5440번째 중....▁의료기관에\n",
      "5450번째 중....▁임금등\n",
      "5460번째 중....▁통합사례관리\n",
      "5470번째 중....▁직업훈련포털\n",
      "5480번째 중....▁mma\n",
      "5490번째 중....▁정서지원\n",
      "5500번째 중....▁SNS\n",
      "5510번째 중....▁선별급여\n",
      "5520번째 중....▁공고문\n",
      "5530번째 중....▁농촌학자\n",
      "5540번째 중....▁아이돌봄서비스\n",
      "5550번째 중....▁mogef\n",
      "5560번째 중....▁단독가구\n",
      "5570번째 중....▁경감대상자\n",
      "5580번째 중....적응훈련\n",
      "5590번째 중....행위로\n",
      "5600번째 중....care\n",
      "5610번째 중....▁물품\n",
      "5620번째 중....▁감염증\n",
      "5630번째 중....▁15669009\n",
      "5640번째 중....▁의무고용률\n",
      "5650번째 중....▁9세24세\n",
      "5660번째 중....인증서\n",
      "5670번째 중....▁SH수협은행\n",
      "5680번째 중....▁18994\n",
      "5690번째 중....연구소\n",
      "5700번째 중....▁취업준비생\n",
      "5710번째 중....▁서민금융통합지원센터\n",
      "5720번째 중....▁04371983988\n",
      "5730번째 중....▁창업보육실\n",
      "5740번째 중....▁인공달팽이관\n",
      "5750번째 중....25세\n",
      "5760번째 중....64세\n",
      "5770번째 중....ar\n",
      "5780번째 중....net\n",
      "5790번째 중....▁긍\n",
      "5800번째 중....▁박\n",
      "5810번째 중....▁헌\n",
      "5820번째 중....▁갈등\n",
      "5830번째 중....건물\n",
      "5840번째 중....교통\n",
      "5850번째 중....내역\n",
      "5860번째 중....대문\n",
      "5870번째 중....동반\n",
      "5880번째 중....레딧\n",
      "5890번째 중....말기\n",
      "5900번째 중....받는\n",
      "5910번째 중....북도\n",
      "5920번째 중....산구\n",
      "5930번째 중....성모병원\n",
      "5940번째 중....시부터\n",
      "5950번째 중....여객선\n",
      "5960번째 중....원을\n",
      "5970번째 중....의위원회\n",
      "5980번째 중....인지\n",
      "5990번째 중....장비\n",
      "6000번째 중....점업\n",
      "6010번째 중....중심\n",
      "6020번째 중....차감\n",
      "6030번째 중....크레딧\n",
      "6040번째 중....폐증\n",
      "6050번째 중....했을\n",
      "6060번째 중....활성화\n",
      "6070번째 중....▁지원과\n",
      "6080번째 중....▁신경\n",
      "6090번째 중....▁원직\n",
      "6100번째 중....장애판정\n",
      "6110번째 중....▁자율\n",
      "6120번째 중....▁390\n",
      "6130번째 중....▁대상에\n",
      "6140번째 중....▁주세요\n",
      "6150번째 중....지원이\n",
      "6160번째 중....▁6인\n",
      "6170번째 중....▁이상을\n",
      "6180번째 중....▁장애인스포츠강좌이용권\n",
      "6190번째 중....▁정당한\n",
      "6200번째 중....에서의\n",
      "6210번째 중....▁15년\n",
      "6220번째 중....▁재일학\n",
      "6230번째 중....▁유행성\n",
      "6240번째 중....▁무보증\n",
      "6250번째 중....▁관광\n",
      "6260번째 중....▁입양한\n",
      "6270번째 중....▁사업지역\n",
      "6280번째 중....▁의료보장\n",
      "6290번째 중....▁임시\n",
      "6300번째 중....▁소진\n",
      "6310번째 중....▁지역신용\n",
      "6320번째 중....▁여유\n",
      "6330번째 중....▁가구는\n",
      "6340번째 중....▁장기간\n",
      "6350번째 중....▁이내의\n",
      "6360번째 중....▁924세\n",
      "6370번째 중....▁포상\n",
      "6380번째 중....▁매분기\n",
      "6390번째 중....▁사회통합\n",
      "6400번째 중....▁출산비용\n",
      "6410번째 중....▁도와\n",
      "6420번째 중....▁온종일돌봄\n",
      "6430번째 중....▁사람에게\n",
      "6440번째 중....▁시군구에\n",
      "6450번째 중....▁16만\n",
      "6460번째 중....▁맞게\n",
      "6470번째 중....▁평생\n",
      "6480번째 중....▁적용제외\n",
      "6490번째 중....▁대학연합\n",
      "6500번째 중....▁양육지원\n",
      "6510번째 중....▁198원\n",
      "6520번째 중....▁청년내일\n",
      "6530번째 중....▁진료가\n",
      "6540번째 중....▁학생의\n",
      "6550번째 중....▁035개월\n",
      "6560번째 중....▁유형으로\n",
      "6570번째 중....▁출생신고\n",
      "6580번째 중....▁실시하기\n",
      "6590번째 중....▁시군구청장이\n",
      "6600번째 중....▁특별히\n",
      "6610번째 중....▁합리\n",
      "6620번째 중....▁학기에\n",
      "6630번째 중....16원\n",
      "6640번째 중....▁설립\n",
      "6650번째 중....▁시도청\n",
      "6660번째 중....▁학습자는\n",
      "6670번째 중....▁재활치료\n",
      "6680번째 중....▁협동조합\n",
      "6690번째 중....▁교육급여를\n",
      "6700번째 중....▁산업기능\n",
      "6710번째 중....▁중앙부처\n",
      "6720번째 중....▁023215\n",
      "6730번째 중....▁일정을\n",
      "6740번째 중....▁CS\n",
      "6750번째 중....▁제주시\n",
      "6760번째 중....▁청소년활동정책\n",
      "6770번째 중....▁외국인근로자\n",
      "6780번째 중....▁사회적관계\n",
      "6790번째 중....▁자살예방\n",
      "6800번째 중....▁말합니다\n",
      "6810번째 중....▁국가보훈관계\n",
      "6820번째 중....▁부여받은\n",
      "6830번째 중....▁창원\n",
      "6840번째 중....▁친환경\n",
      "6850번째 중....▁카드사용\n",
      "6860번째 중....▁신청일이\n",
      "6870번째 중....▁업종전환자\n",
      "6880번째 중....▁289\n",
      "6890번째 중....3430\n",
      "6900번째 중....▁독거어르신\n",
      "6910번째 중....▁상속인에게\n",
      "6920번째 중....▁금연\n",
      "6930번째 중....▁15세24세\n",
      "6940번째 중....▁눈건강\n",
      "6950번째 중....▁상실한\n",
      "6960번째 중....▁중증난치질환\n",
      "6970번째 중....▁향상\n",
      "6980번째 중....▁심장질환\n",
      "6990번째 중....▁철분\n",
      "7000번째 중....▁연료비\n",
      "7010번째 중....▁15770900\n",
      "7020번째 중....▁레인보우스\n",
      "7030번째 중....▁04420\n",
      "7040번째 중....▁교재교구\n",
      "7050번째 중....▁협력체계\n",
      "7060번째 중....▁클래스\n",
      "7070번째 중....▁입국한\n",
      "7080번째 중....▁보호종료아동\n",
      "7090번째 중....▁역량강화교육\n",
      "7100번째 중....▁풍수\n",
      "7110번째 중....▁유관기관\n",
      "7120번째 중....▁긴급틈새돌봄\n",
      "7130번째 중....▁산업재해로\n",
      "7140번째 중....▁일반연령반은\n",
      "7150번째 중....▁정해져\n",
      "7160번째 중....▁적절한\n",
      "7170번째 중....▁지역사회통합돌봄\n",
      "7180번째 중....▁긴급복지지원법에\n",
      "7190번째 중....milynet\n",
      "7200번째 중....▁familynet\n",
      "7210번째 중....▁klac\n",
      "7220번째 중....▁806만\n",
      "7230번째 중....▁15779337\n",
      "7240번째 중....▁023215579\n",
      "7250번째 중....▁레인보우스쿨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(35316, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary 불러오기\n",
    "added_vocab_df = pd.read_json('./tokenizer/vocab.json', orient='index')\n",
    "\n",
    "added_vocab_list = []    # 여기에 추가할 단어들 담을거\n",
    "chk_idx = 0    # 로그 찍기용 index\n",
    "\n",
    "for new_word in added_vocab_df.index.to_list():\n",
    "    # 로그 찍기 (10번에 한 번씩)\n",
    "    chk_idx += 1\n",
    "    if not chk_idx % 10:\n",
    "        print(f\"{chk_idx}번째 중....{new_word}\")\n",
    "\n",
    "    if '▁' in new_word:\n",
    "        test_word = new_word.replace('▁', '')\n",
    "    else:\n",
    "        test_word = new_word\n",
    "    test_word = test_word.strip()\n",
    "    # 이미 vocab에 있는 단어 & 1글자인거 빼고 vocab에 추가\n",
    "    if test_word not in tokenizer_base.vocab.keys() and len(test_word) > 1:\n",
    "        added_vocab_list.append(new_word.replace('▁', ''))\n",
    "\n",
    "# 혹시 모르니 백업\n",
    "import pickle\n",
    "\n",
    "with open('./tokenizer/added_vocab_list.pickle', 'wb') as fw:\n",
    "    pickle.dump(added_vocab_list, fw)\n",
    "\n",
    "# 본격 토큰 추가\n",
    "\n",
    "# 앞에서 했던 코드 까먹었을까봐 다시 적음\n",
    "# base_model_path = \"../workspace/da_finetune_epoch_2\"\n",
    "# model = SentenceTransformer(base_model_path)\n",
    "# word_embedding_model = model._first_module()\n",
    "\n",
    "word_embedding_model.tokenizer.add_tokens(added_vocab_list, special_tokens=False)\n",
    "word_embedding_model.auto_model.resize_token_embeddings(len(word_embedding_model.tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 33044, 3604, 34243, 3642, 32345, 1498, 6470, 34102, 6484, 2104, 2102, 2069, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaptation 하기 전 Tokenize 결과\n",
    "word_embedding_model.tokenizer(test_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000\n",
      "35316\n",
      "Embedding(32000, 768, padding_idx=1)\n",
      "Embedding(35316, 768)\n",
      "['[CLS]', '행복주택', '에서', '미소금융', '이나', '햇살론', '을', '농협', '은행에서', '담보', '##대', '##출', '##을', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModel, AutoTokenizer\n",
    "# base_model_path = '../workspace/da_finetune_epoch_2'\n",
    "# model_base = AutoModel.from_pretrained(base_model_path)\n",
    "# tokenizer_base = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "# 토큰들 추가\n",
    "print(len(tokenizer_base.vocab))\n",
    "added_token_num = tokenizer_base.add_tokens(added_vocab_list)\n",
    "print(len(tokenizer_base.vocab))\n",
    "\n",
    "# model에도 바뀐거 적용\n",
    "print(model_base.get_input_embeddings())\n",
    "model_base.resize_token_embeddings(tokenizer_base.vocab_size + added_token_num)\n",
    "print(model_base.get_input_embeddings())\n",
    "\n",
    "# id -> word 바꾸도록 dictionary 생성\n",
    "vocab_id_2_word = {v: k for k, v in tokenizer_base.vocab.items()}\n",
    "# dictionary 이용해서 아까 나온 결과 확인\n",
    "input_ids = word_embedding_model.tokenizer(test_sentence)['input_ids']\n",
    "print([vocab_id_2_word[t_id] for t_id in input_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './workspace/epoch_tok'\n",
    "model_name = 'epoch_tok'\n",
    "model.save(path=save_path, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '행복주택', '에서', '미소금융', '이나', '햇살론', '을', '농협', '은행에서', '담보', '##대', '##출', '##을', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "new_model = SentenceTransformer(save_path)\n",
    "new_word_embedding_model = new_model._first_module()\n",
    "\n",
    "input_ids = new_word_embedding_model.tokenizer(test_sentence)['input_ids']\n",
    "\n",
    "print([vocab_id_2_word[t_id] for t_id in input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers import losses\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = './da_train/da_train_dataset.json'\n",
    "val_dataset_path = './da_train/da_val_dataset.json'\n",
    "\n",
    "#BATCH_SIZE\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_dataset_path, 'r+', encoding='utf-8') as f :\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(val_dataset_path, 'r', encoding='utf-8') as f :\n",
    "    val_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train_dataset['corpus']\n",
    "queries = train_dataset['queries']\n",
    "relevant_docs = train_dataset['relevant_docs']\n",
    "\n",
    "examples = []\n",
    "\n",
    "for query_id, query in queries.items():\n",
    "    node_id = relevant_docs[query_id][0]\n",
    "    text = corpus[node_id]\n",
    "    example = InputExample(texts=[query, text])\n",
    "    examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    examples, batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.MultipleNegativesRankingLoss(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "\n",
    "corpus = val_dataset['corpus']\n",
    "queries = val_dataset['queries']\n",
    "relevant_docs = val_dataset['relevant_docs']\n",
    "\n",
    "evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch config\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31d236eca264aa7ba76f0044a7b2009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5157b04acdce428cb921a318812b1294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jk/CODE/toc_ad/test.ipynb 셀 19\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#memory allocation error\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     train_objectives\u001b[39m=\u001b[39;49m[(loader, loss)],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     warmup_steps\u001b[39m=\u001b[39;49mwarmup_steps,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     output_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./da_finetune\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     evaluator\u001b[39m=\u001b[39;49mevaluator, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     evaluation_steps\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jk/CODE/toc_ad/test.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ssis/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:722\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    721\u001b[0m     loss_value \u001b[39m=\u001b[39m loss_model(features, labels)\n\u001b[0;32m--> 722\u001b[0m     loss_value\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    723\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(loss_model\u001b[39m.\u001b[39mparameters(), max_grad_norm)\n\u001b[1;32m    724\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/ssis/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ssis/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "#memory allocation error\n",
    "model.to('mps')\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='./da_finetune',\n",
    "    show_progress_bar=True,\n",
    "    evaluator=evaluator, \n",
    "    evaluation_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
